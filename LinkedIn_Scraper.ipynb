{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb746f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Imports\n",
    "###########################################\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from parsel import Selector\n",
    "from bs4 import BeautifulSoup\n",
    "import os, time, random, json, re\n",
    "from csv import writer\n",
    "from time import sleep\n",
    "import tkinter as tk\n",
    "\n",
    "#Selenium imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e933ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Logging In\n",
    "###########################################\n",
    "\n",
    "# First thing to do is to login the credentials of LinkedIn\n",
    "def login():\n",
    "    driver.get('https://www.linkedin.com/login')\n",
    "    time.sleep(random.choice(random_time_list_1)) \n",
    "    username = driver.find_element(By.ID,'username')\n",
    "    username.send_keys('yourEmails')\n",
    "    password = driver.find_element(By.ID,'password')\n",
    "    password.send_keys('yourPassword')\n",
    "    time.sleep(random.choice(random_time_list_1)) \n",
    "    password.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d76f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Researching IT professionals on LinkedIn\n",
    "###########################################\n",
    "\n",
    "def search(query):\n",
    "    # Task 2: Search for the profile we want to crawl\n",
    "    # Task 2.1: Locate the search bar element\n",
    "    sleep(2)\n",
    "    wait = WebDriverWait(driver, 4)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            search_field = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"global-nav-typeahead\"]/input')))\n",
    "            time.sleep(0.2)\n",
    "            # Task 2.2: Input the search query to the search bar\n",
    "            # search_query = input('What profile do you want to scrape? ')\n",
    "            search_field.send_keys(query)\n",
    "            # Task 2.3: Search\n",
    "            search_field.send_keys(Keys.RETURN)\n",
    "            break\n",
    "        except:\n",
    "            sleep(1)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            people = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"search-reusables__filters-bar\"]/ul/li[1]/button')))\n",
    "            people.click()\n",
    "            time.sleep(0.2)       \n",
    "            break\n",
    "        except:\n",
    "            sleep(1)\n",
    "   \n",
    "    \n",
    "    sleep(2)\n",
    "    current_url=driver.current_url\n",
    "    return(current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8620b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Extract experiences\n",
    "##################################\n",
    "\n",
    "def extract_experiences(experience_tags):\n",
    "    \n",
    "    experience_list = []\n",
    "\n",
    "    order = 1\n",
    "    for exp_tag in experience_tags:\n",
    "        experience_div = exp_tag.parent.parent\n",
    "        experience_div = [*experience_div.children][3]\n",
    "\n",
    "        try:\n",
    "            if experience_div.div.a is not None:\n",
    "                # Multiple job position within same company\n",
    "                multi_job = experience_div.find_all(\"div\", class_=\"display-flex align-items-center\") #.span.span\n",
    "                company = multi_job[0].span.span\n",
    "                job_title = multi_job[1].span.span\n",
    "                job_type = experience_div.find(\"span\", class_=\"t-14 t-normal\").span\n",
    "\n",
    "                job_title = re.search(r_expression, str(job_title)).group(0)\n",
    "                company = re.search(r_expression, str(company)).group(0)\n",
    "                job_type = re.search(r_expression, str(job_type)).group(0)\n",
    "                job_type = job_type.split('·')[0] if '·' in job_type else job_type\n",
    "\n",
    "                # experience_list.append((job_title, company, *[c.strip() for c in job_type.split('·')][::-1]))\n",
    "                experience_list.append(\n",
    "                    {\n",
    "                        \"job_title\": job_title,\n",
    "                        \"company\": company,\n",
    "                        \"job_type\": job_type.split('·')[0].strip() if '·' in job_type else None,\n",
    "                        \"job_duration\": job_type.split('·')[1].strip() if '·' in job_type else job_type,\n",
    "                        \"order\": order\n",
    "                    }  \n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            pass\n",
    "            print(e)\n",
    "        try:\n",
    "            if experience_div.div.div is not None:\n",
    "                job_title = experience_div.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\").span\n",
    "                \n",
    "                company = experience_div.find(\"span\", class_=\"t-14 t-normal\").span\n",
    "                duration = experience_div.find(\"span\", class_=\"t-14 t-normal t-black--light\").span\n",
    "\n",
    "          \n",
    "                job_title = re.search(r_expression, str(job_title)).group(0)\n",
    "                company = re.search(r_expression, str(company)).group(0)\n",
    "                duration = re.search(r_expression, str(duration)).group(0)\n",
    "\n",
    "                # experience_list.append((job_title, *[c.strip() for c in company.split('·')][::-1], duration.split('·')[-1].strip()))\n",
    "                experience_list.append(\n",
    "                    {\n",
    "                        \"job_title\": job_title.strip(),\n",
    "                        \"company\": company.split('·')[0].strip() if '·' in company else company,\n",
    "                        \"job_type\": company.split('·')[1].strip() if '·' in company else None,\n",
    "                        \"job_duration\": duration.split('·')[-1].strip(),\n",
    "                        \"order\": order\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print(e)\n",
    "        order += 1\n",
    "\n",
    "    return experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ef687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Extract other achievements\n",
    "##################################\n",
    "\n",
    "def extract_achievements(head_section, category):\n",
    "    achievement_list = []\n",
    "\n",
    "    # if category == \"education\" or category == \"certification\":\n",
    "    achievement_tags = head_section.find_all(\"a\", class_=\"optional-action-target-wrapper display-flex flex-column full-width\")\n",
    "    achievement_tags += head_section.find_all(\"div\", class_=\"display-flex flex-column full-width\")\n",
    "\n",
    "    order = 1\n",
    "    for tag in achievement_tags:\n",
    "        institute = tag.div.span\n",
    "        # full xpath /html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[4]/div[3]/ul/li[1]/div/div[2]/div/a/div/div/div/div/span[1]\n",
    "        # old path : institute = tag.div.span.span\n",
    "        # print('institute before formatting: '+str(institute))\n",
    "\n",
    "        title = tag.find(\"span\", class_=\"t-14 t-normal\")\n",
    "        title = title.span if title else None\n",
    "\n",
    "        title = re.search(r_expression, str(title))\n",
    "        title = title.group(0) if title else None\n",
    "        institute = re.search(r_expression, str(institute))\n",
    "        institute = institute.group(0) if institute else None\n",
    "        # print('institute : '+str(institute))\n",
    "        # print('title : '+ str(title))\n",
    "        if category == \"education\":\n",
    "            achievement_list.append(\n",
    "                {\n",
    "                    \"title\": title,\n",
    "                    \"institute\": institute,\n",
    "                    \"order\": order\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            # linkedin made this\n",
    "            achievement_list.append(\n",
    "                {\n",
    "                    \"title\": institute,\n",
    "                    \"institute\": title,\n",
    "                    \"order\": order\n",
    "                }\n",
    "            )\n",
    "        order += 1\n",
    "\n",
    "    return achievement_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a69f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Scrapping the profiles of IT professionals and their projects\n",
    "#################################################################\n",
    "\n",
    "def scrape_profiles():\n",
    "    df_profile = pd.DataFrame()\n",
    "    df_experiences = pd.DataFrame()\n",
    "    df_education = pd.DataFrame()\n",
    "    df_certification = pd.DataFrame()\n",
    "    df_courses = pd.DataFrame()\n",
    "\n",
    "    final_profiles_list = []\n",
    "    undesirable_key_words = ['feed','mynetwork','jobs','messaging','notifications','premium','products', 'sales', 'story', 'company', 'results', 'people']\n",
    "    desirable_countries = ['Canada','United States', 'Belgium', 'Bulgaria', 'Croatia', 'Czech Republic', 'Denmark', \n",
    "                           'Germany', 'Estonia', 'Greece', 'Spain', 'France', 'Ireland', 'Italy', 'Cyprus', 'Latvia', \n",
    "                           'Lithuania', 'Luxembourg', 'Hungary', 'Malta', 'The Netherlands', 'Austria', 'Poland', \n",
    "                           'Portugal', 'Romania', 'Slovenia', 'Slovakia', 'Finland' , 'Sweden' , 'Tunisia']\n",
    "   \n",
    "    #Extracting profiles URLs\n",
    "    profiles = driver.find_elements(By.CLASS_NAME, 'app-aware-link')\n",
    "   \n",
    "    all_profile_URL = []\n",
    "   \n",
    "    for profile in profiles:\n",
    "        profile_URL = profile.get_attribute('href')\n",
    "        if (profile_URL not in all_profile_URL):\n",
    "            bool_var = True\n",
    "            for key_word in undesirable_key_words:\n",
    "                if (profile_URL.find(key_word)!=-1) :\n",
    "                    bool_var = False\n",
    "            \n",
    "            if ((bool_var) and (profile_URL not in all_profile_URL) and (profile_URL.find('linkedin')!=-1)):\n",
    "                all_profile_URL.append(profile_URL)\n",
    "        \n",
    "            \n",
    "    # For loop to iterate over each URL in the list\n",
    "    all_profile_URL = list(set(all_profile_URL))\n",
    "    for profile in all_profile_URL:\n",
    "        driver.get(profile)\n",
    "        scroll_indicator = 0\n",
    "        while scroll_indicator < 10:                        \n",
    "            driver.execute_script(\"window.scrollBy(0, arguments[0]);\", 600)\n",
    "            scroll_indicator += 1\n",
    "            time.sleep(random.choice(random_time_list_2))\n",
    "        \n",
    "    \n",
    "        soup = BeautifulSoup(driver.page_source, \"lxml\")          \n",
    "        # Extract basic info\n",
    "        time.sleep(random.choice(random_time_list_1))\n",
    "        \n",
    "        profile_cards = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view pv-top-card\"})\n",
    "        if ((profile_cards) and (driver.current_url not in final_profiles_list)):\n",
    "            final_profiles_list.append(driver.current_url)\n",
    "            profile_card = profile_cards[0]\n",
    "            name = profile_card.find(\"div\", class_=\"pv-text-details__left-panel\").div.h1.string.strip()\n",
    "            location = profile_card.find(\"div\", class_=\"pv-text-details__left-panel mt2\").span.string.strip()\n",
    "            designation = profile_card.find(\"div\", class_=\"text-body-medium break-words\").string.strip()\n",
    "            country = (location.split(','))[-1].strip()\n",
    "            \n",
    "            if country in desirable_countries:\n",
    "                \n",
    "                df = pd.DataFrame({\"profile\": driver.current_url,\"name\": name, \"location\": location, \"designation\": designation}, index=[0])\n",
    "                df_profile = pd.concat([df_profile, df], ignore_index=True, axis=0)\n",
    "\n",
    "                sections =  soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view relative break-words pb3 mt2\"})\n",
    "                for section in sections:\n",
    "                            # Extract E\n",
    "                            if section.div[\"id\"] == \"experience\":\n",
    "                                print(\"found experience\")\n",
    "                                experiences = section.find_all(\"a\", {\"data-field\": \"experience_company_logo\", \"class\": \"optional-action-target-wrapper display-flex\"})\n",
    "                                if len(experiences):\n",
    "                                    experiences_json = extract_experiences(experiences)\n",
    "                                    df = pd.DataFrame(data=experiences_json)\n",
    "                                    df['profile'] = driver.current_url\n",
    "                                    df_experiences = pd.concat([df_experiences, df], ignore_index=True, axis=0)\n",
    "                            # Extract educations\n",
    "                            if section.div[\"id\"] == \"education\":\n",
    "                                print(\"found education\")\n",
    "                                educations_json = extract_achievements(section, \"education\")\n",
    "                                df = pd.DataFrame(data=educations_json)\n",
    "                                df['profile'] = driver.current_url\n",
    "                                df_education = pd.concat([df_education, df], ignore_index=True, axis=0)\n",
    "                            if section.div[\"id\"] == \"licenses_and_certifications\":\n",
    "                                print(\"found certifications\")\n",
    "                                certifications_json = extract_achievements(section, \"certification\")\n",
    "                                df = pd.DataFrame(data=certifications_json)\n",
    "                                df['profile'] = driver.current_url\n",
    "                                df_certification = pd.concat([df_certification, df], ignore_index=True, axis=0)\n",
    "                            elif section.div[\"id\"] == \"courses\":\n",
    "                                print(\"found courses\")\n",
    "                                courses_json = extract_achievements(section, \"courses\")\n",
    "                                df = pd.DataFrame(data=courses_json)\n",
    "                                df['profile'] = driver.current_url\n",
    "                                df_courses = pd.concat([df_courses, df], ignore_index=True, axis=0)\n",
    "                                \n",
    "                        \n",
    "\n",
    "                \n",
    "                time.sleep(random.choice(random_time_list_1))  \n",
    "                \n",
    "    # Adding all informations to dataset \n",
    "    display(df_profile)\n",
    "    display(df_experiences)                                   \n",
    "    display(df_education)                     \n",
    "    display(df_certification)\n",
    "    display(df_courses)\n",
    "    print(\"Writing dataframes to csv\")\n",
    "    df_profile.to_csv('/home/yassine/Desktop/End of studies Project/Scraped data/scraped_profiles.csv',mode='a', index=False, header=False)\n",
    "    df_experiences.to_csv('/home/yassine/Desktop/End of studies Project/Scraped data/scraped_experiences.csv',mode='a', index=False, header=False)\n",
    "    df_education.to_csv('/home/yassine/Desktop/End of studies Project/Scraped data/scraped_education.csv',mode='a', index=False, header=False)\n",
    "    df_certification.to_csv('/home/yassine/Desktop/End of studies Project/Scraped data/scraped_certification.csv',mode='a', index=False, header=False)\n",
    "    df_courses.to_csv('/home/yassine/Desktop/End of studies Project/Scraped data/scraped_courses.csv',mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a032689",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Navigating the next page\n",
    "##################################\n",
    "\n",
    "def navigate_next_page(page_number,page_URL):\n",
    "    driver.get(page_URL)\n",
    "    time.sleep(random.choice(random_time_list_1)) \n",
    "    wait = WebDriverWait(driver, 4)\n",
    "    while True:\n",
    "        try:\n",
    "            next_btn = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"button.artdeco-pagination__button.artdeco-pagination__button--next\")))\n",
    "            next_btn.location_once_scrolled_into_view\n",
    "            time.sleep(random.choice(random_time_list_2)) \n",
    "            next_btn.click()\n",
    "            break\n",
    "        except:\n",
    "            driver.execute_script(\"window.scrollBy(0, arguments[0]);\", 600)\n",
    "    time.sleep(random.choice(random_time_list_1)) \n",
    "    \n",
    "    print('Going to next page')\n",
    "    \n",
    "    current_url=driver.current_url\n",
    "    return current_url\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45724f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Core programe\n",
    "##################################\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "def core_prog():\n",
    "    # Login to LinkedIn\n",
    "    login()\n",
    "    time.sleep(5)\n",
    "    # Scrape the profiles of IT professionals and their projects, using for loop to loop over all pages\n",
    "    page_number=1\n",
    "    # Search for IT professionals\n",
    "    page_URL=search(' Software engineer AND :location=europe')\n",
    "    while (page_number<10):\n",
    "        time.sleep(random.choice(random_time_list_1)) \n",
    "        scrape_profiles()\n",
    "        time.sleep(random.choice(random_time_list_1)) \n",
    "        page_number+=1 \n",
    "        #Navigating to the next corresponding page\n",
    "        new_page_URL=navigate_next_page(page_number,page_URL)\n",
    "        print('Navigating to page :' + str(page_number))\n",
    "        page_URL= new_page_URL\n",
    "        time.sleep(random.choice(random_time_list_1)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d9e2d60",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     search_field \u001b[39m=\u001b[39m wait\u001b[39m.\u001b[39;49muntil(EC\u001b[39m.\u001b[39;49mpresence_of_element_located((By\u001b[39m.\u001b[39;49mXPATH, \u001b[39m'\u001b[39;49m\u001b[39m//*[@id=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mglobal-nav-typeahead\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]/input\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[1;32m     14\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.2\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/selenium/webdriver/support/wait.py:86\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     value \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_driver)\n\u001b[1;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m value:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/selenium/webdriver/support/expected_conditions.py:69\u001b[0m, in \u001b[0;36mpresence_of_element_located.<locals>._predicate\u001b[0;34m(driver)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predicate\u001b[39m(driver):\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mreturn\u001b[39;00m driver\u001b[39m.\u001b[39;49mfind_element(\u001b[39m*\u001b[39;49mlocator)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/selenium/webdriver/remote/webdriver.py:830\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    828\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 830\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mInvalidSessionIdException\u001b[0m: Message: Tried to run command without establishing a connection\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Create the Firefox WebDriver\u001b[39;00m\n\u001b[1;32m     21\u001b[0m driver\u001b[39m.\u001b[39mmaximize_window()\n\u001b[0;32m---> 22\u001b[0m core_prog()\n\u001b[1;32m     23\u001b[0m driver\u001b[39m.\u001b[39mquit()\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mcore_prog\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m page_number\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Search for IT professionals\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m page_URL\u001b[39m=\u001b[39msearch(\u001b[39m'\u001b[39;49m\u001b[39m Software engineer AND :location=europe\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m \u001b[39mwhile\u001b[39;00m (page_number\u001b[39m<\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[1;32m     15\u001b[0m     time\u001b[39m.\u001b[39msleep(random\u001b[39m.\u001b[39mchoice(random_time_list_1)) \n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m         sleep(\u001b[39m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Main program\n",
    "##################################\n",
    "r_expression = r\"(?<=-\\>)[0-9a-zA-Z ,éÉèàçÀâäêëîïôöùûüÿ':·-]+\"\n",
    "random_time_list_1 = [ 4, 5, 6, 7, 8, 9 ]\n",
    "random_time_list_2 = [ 0.3, 0.6, 0.9, 1.2, 1.5,  1.8 ]\n",
    "\n",
    "# Set up the web driver\n",
    "\n",
    "firefox_binary_path = \"/usr/bin/firefox\"\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = firefox_binary_path\n",
    "\n",
    "# Set the service with the executable path\n",
    "geckodriver_path = \"/usr/local/bin/geckodriver\"  # Replace with the actual path of geckodriver\n",
    "service = webdriver.firefox.service.Service(geckodriver_path)\n",
    "driver = webdriver.Firefox(options=options, service=service)\n",
    "\n",
    "# Create the Firefox WebDriver\n",
    "driver.maximize_window()\n",
    "core_prog()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5637d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
