{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb746f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Imports\n",
    "###########################################\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from parsel import Selector\n",
    "from bs4 import BeautifulSoup\n",
    "import os, time, random, json, re\n",
    "from csv import writer\n",
    "from time import sleep\n",
    "import tkinter as tk\n",
    "\n",
    "#Selenium imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e933ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Logging In\n",
    "###########################################\n",
    "\n",
    "# First thing to do is to login the credentials of LinkedIn\n",
    "def login():\n",
    "    driver.get('https://www.linkedin.com/login')\n",
    "    time.sleep(5)\n",
    "    username = driver.find_element(By.ID,'username')\n",
    "    username.send_keys('mharrek.yassine@gmail.com')\n",
    "    password = driver.find_element(By.ID,'password')\n",
    "    password.send_keys('$E?Mry;WuHv8K3_')\n",
    "    time.sleep(5)\n",
    "    password.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d76f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Researching IT professionals on LinkedIn\n",
    "###########################################\n",
    "\n",
    "def search(query):\n",
    "    # Task 2: Search for the profile we want to crawl\n",
    "    # Task 2.1: Locate the search bar element\n",
    "    sleep(2)\n",
    "    wait = WebDriverWait(driver, 4)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            search_field = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"global-nav-typeahead\"]/input')))\n",
    "            time.sleep(0.2)\n",
    "            # Task 2.2: Input the search query to the search bar\n",
    "            # search_query = input('What profile do you want to scrape? ')\n",
    "            search_field.send_keys(query)\n",
    "            # Task 2.3: Search\n",
    "            search_field.send_keys(Keys.RETURN)\n",
    "            break\n",
    "        except:\n",
    "            sleep(1)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            people = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"search-reusables__filters-bar\"]/ul/li[3]/button')))\n",
    "            people.click()\n",
    "            time.sleep(0.2)       \n",
    "            break\n",
    "        except:\n",
    "            sleep(1)\n",
    "   \n",
    "    \n",
    "    sleep(2)\n",
    "    current_url=driver.current_url\n",
    "    return(current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8620b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Extract experiences\n",
    "##################################\n",
    "\n",
    "def extract_experiences(experience_tags):\n",
    "    \n",
    "    experience_list = []\n",
    "\n",
    "    order = 1\n",
    "    for exp_tag in experience_tags:\n",
    "        experience_div = exp_tag.parent.parent\n",
    "        experience_div = [*experience_div.children][3]\n",
    "\n",
    "        try:\n",
    "            if experience_div.div.a is not None:\n",
    "                # Multiple job position within same company\n",
    "                multi_job = experience_div.find_all(\"div\", class_=\"display-flex align-items-center\") #.span.span\n",
    "                company = multi_job[0].span.span\n",
    "                job_title = multi_job[1].span.span\n",
    "                job_type = experience_div.find(\"span\", class_=\"t-14 t-normal\").span\n",
    "\n",
    "                job_title = re.search(r_expression, str(job_title)).group(0)\n",
    "                company = re.search(r_expression, str(company)).group(0)\n",
    "                job_type = re.search(r_expression, str(job_type)).group(0)\n",
    "                job_type = job_type.split('·')[0] if '·' in job_type else job_type\n",
    "\n",
    "                # experience_list.append((job_title, company, *[c.strip() for c in job_type.split('·')][::-1]))\n",
    "                experience_list.append(\n",
    "                    {\n",
    "                        \"job_title\": job_title,\n",
    "                        \"company\": company,\n",
    "                        \"job_type\": job_type.split('·')[0].strip() if '·' in job_type else None,\n",
    "                        \"job_duration\": job_type.split('·')[1].strip() if '·' in job_type else job_type,\n",
    "                        \"order\": order\n",
    "                    }  \n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            pass\n",
    "            print(e)\n",
    "        try:\n",
    "            if experience_div.div.div is not None:\n",
    "                job_title = experience_div.find(\"div\", class_=\"display-flex align-items-center mr1 t-bold\").span\n",
    "                \n",
    "                company = experience_div.find(\"span\", class_=\"t-14 t-normal\").span\n",
    "                duration = experience_div.find(\"span\", class_=\"t-14 t-normal t-black--light\").span\n",
    "\n",
    "          \n",
    "                job_title = re.search(r_expression, str(job_title)).group(0)\n",
    "                company = re.search(r_expression, str(company)).group(0)\n",
    "                duration = re.search(r_expression, str(duration)).group(0)\n",
    "\n",
    "                # experience_list.append((job_title, *[c.strip() for c in company.split('·')][::-1], duration.split('·')[-1].strip()))\n",
    "                experience_list.append(\n",
    "                    {\n",
    "                        \"job_title\": job_title.strip(),\n",
    "                        \"company\": company.split('·')[0].strip() if '·' in company else company,\n",
    "                        \"job_type\": company.split('·')[1].strip() if '·' in company else None,\n",
    "                        \"job_duration\": duration.split('·')[-1].strip(),\n",
    "                        \"order\": order\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print(e)\n",
    "        order += 1\n",
    "\n",
    "    return experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16ef687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Extract other achievements\n",
    "##################################\n",
    "\n",
    "def extract_achievements(head_section, category):\n",
    "    achievement_list = []\n",
    "    if category == \"education\" or category == \"certification\" or category == \"courses\":\n",
    "        achievement_tags = head_section.find_all(\"a\", class_=\"optional-action-target-wrapper display-flex flex-column full-width\")\n",
    "        achievement_tags += head_section.find_all(\"div\", class_=\"display-flex flex-column full-width\")\n",
    "\n",
    "        order = 1\n",
    "        for tag in achievement_tags:\n",
    "            institute = tag.div.span.span\n",
    "            print(institute)\n",
    "            title = tag.find(\"span\", class_=\"t-14 t-normal\")\n",
    "            \n",
    "            if (title):\n",
    "                title = title.span\n",
    "                print(title)\n",
    "            else :\n",
    "                title = None\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            institute = institute.group(0) if institute else None\n",
    "\n",
    "            if category == \"education\":\n",
    "                achievement_list.append(\n",
    "                    {\n",
    "                        \"title\": title,\n",
    "                        \"institute\": institute,\n",
    "                        \"order\": order\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                # linkedin made this\n",
    "                achievement_list.append(\n",
    "                    {\n",
    "                        \"title\": institute,\n",
    "                        \"institute\": title,\n",
    "                        \"order\": order\n",
    "                    }\n",
    "                )\n",
    "            order += 1\n",
    "\n",
    "    return achievement_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a69f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Scrapping the profiles of IT professionals and their projects\n",
    "#################################################################\n",
    "\n",
    "def scrape_profiles():\n",
    "    df_profile = pd.DataFrame()\n",
    "    df_experiences = pd.DataFrame()\n",
    "    df_education = pd.DataFrame()\n",
    "    df_certification = pd.DataFrame()\n",
    "    df_courses = pd.DataFrame()\n",
    "    random_time_list_1 = [1, 2, 3, 4, 5, 6]\n",
    "    random_time_list_2 = [0.6, 0.5, 0.8, 1.4, 0.15, 1]\n",
    "    final_profiles_list = []\n",
    "    undesirable_key_words = ['feed','mynetwork','jobs','messaging','notifications','premium','products', 'sales', 'story', 'company']\n",
    "    desirable_countries = ['Canada','United States', 'Belgium', 'Bulgaria', 'Croatia', 'Czech Republic', 'Denmark', \n",
    "                           'Germany', 'Estonia', 'Greece', 'Spain', 'France', 'Ireland', 'Italy', 'Cyprus', 'Latvia', \n",
    "                           'Lithuania', 'Luxembourg', 'Hungary', 'Malta', 'The Netherlands', 'Austria', 'Poland', \n",
    "                           'Portugal', 'Romania', 'Slovenia', 'Slovakia', 'Finland' , 'Sweden' , 'Tunisia']\n",
    "   \n",
    "    #Extracting profiles URLs\n",
    "    profiles = driver.find_elements(By.CLASS_NAME, 'app-aware-link')\n",
    "   \n",
    "    all_profile_URL = []\n",
    "   \n",
    "    for profile in profiles:\n",
    "        profile_URL = profile.get_attribute('href')\n",
    "        if (profile_URL not in all_profile_URL):\n",
    "            bool_var = True\n",
    "            for key_word in undesirable_key_words:\n",
    "                if (profile_URL.find(key_word)!=-1) :\n",
    "                    bool_var = False\n",
    "            \n",
    "            if ((bool_var) and (profile_URL not in all_profile_URL) and (profile_URL.find('linkedin')!=-1)):\n",
    "                all_profile_URL.append(profile_URL)\n",
    "        \n",
    "            \n",
    "    # For loop to iterate over each URL in the list\n",
    "    all_profile_URL = list(set(all_profile_URL))\n",
    "    for profile in all_profile_URL:\n",
    "        driver.get(profile)\n",
    "        scroll_indicator = 0\n",
    "        while scroll_indicator < 10:                        \n",
    "            driver.execute_script(\"window.scrollBy(0, arguments[0]);\", 600)\n",
    "            scroll_indicator += 1\n",
    "            time.sleep(random.choice(random_time_list_2))\n",
    "        \n",
    "    \n",
    "        soup = BeautifulSoup(driver.page_source, \"lxml\")          \n",
    "        # Extract basic info\n",
    "        time.sleep(random.choice(random_time_list_1))\n",
    "        \n",
    "        profile_cards = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view pv-top-card\"})\n",
    "        if ((profile_cards) and (driver.current_url not in final_profiles_list)):\n",
    "            final_profiles_list.append(driver.current_url)\n",
    "            profile_card = profile_cards[0]\n",
    "            name = profile_card.find(\"div\", class_=\"pv-text-details__left-panel\").div.h1.string.strip()\n",
    "            location = profile_card.find(\"div\", class_=\"pv-text-details__left-panel mt2\").span.string.strip()\n",
    "            designation = profile_card.find(\"div\", class_=\"text-body-medium break-words\").string.strip()\n",
    "            country = (location.split(','))[-1].strip()\n",
    "            \n",
    "            if country in desirable_countries:\n",
    "                \n",
    "                df = pd.DataFrame({\"profile\": driver.current_url,\"name\": name, \"location\": location, \"designation\": designation}, index=[0])\n",
    "                df_profile = pd.concat([df_profile, df], ignore_index=True, axis=0)\n",
    "\n",
    "                sections =  soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view relative break-words pb3 mt2\"})\n",
    "                for section in sections:\n",
    "                            # Extract E\n",
    "                            if section.div[\"id\"] == \"experience\":\n",
    "                                print(\"found experience\")\n",
    "                                experiences = section.find_all(\"a\", {\"data-field\": \"experience_company_logo\", \"class\": \"optional-action-target-wrapper display-flex\"})\n",
    "                                if len(experiences):\n",
    "                                    experiences_json = extract_experiences(experiences)\n",
    "                                    df = pd.DataFrame(data=experiences_json)\n",
    "                                    df['profile'] = driver.current_url\n",
    "                                    df_experiences = pd.concat([df_experiences, df], ignore_index=True, axis=0)\n",
    "                            # Extract educations\n",
    "                            if section.div[\"id\"] == \"education\":\n",
    "                                print(\"found education\")\n",
    "                                educations_json = extract_achievements(section, \"education\")\n",
    "                                df = pd.DataFrame(data=educations_json)\n",
    "                                df['profile'] = driver.current_url\n",
    "                                df_education = pd.concat([df_education, df], ignore_index=True, axis=0)\n",
    "                            if section.div[\"id\"] == \"licenses_and_certifications\":\n",
    "                                print(\"found certifications\")\n",
    "                                certifications_json = extract_achievements(section, \"certification\")\n",
    "                                df = pd.DataFrame(data=certifications_json)\n",
    "                                df['profile'] = driver.current_url\n",
    "                                df_certification = pd.concat([df_certification, df], ignore_index=True, axis=0)\n",
    "                            elif section.div[\"id\"] == \"courses\":\n",
    "                                print(\"found courses\")\n",
    "                                courses_json = extract_achievements(section, \"courses\")\n",
    "                                df = pd.DataFrame(data=courses_json)\n",
    "                                df['profile'] = driver.current_url\n",
    "                                df_courses = pd.concat([df_courses, df], ignore_index=True, axis=0)\n",
    "                                \n",
    "                        \n",
    "\n",
    "                \n",
    "                time.sleep(random.choice(random_time_list_1))  \n",
    "                \n",
    "    # Adding all informations to dataset \n",
    "    display(df_profile)\n",
    "    display(df_experiences)                                   \n",
    "    display(df_education)                     \n",
    "    display(df_certification)\n",
    "    display(df_courses)\n",
    "    print(\"Writing dataframes to csv\")\n",
    "    df_profile.to_csv('/home/yassine/Desktop/End of studies Project/scraped_profiles.csv',mode='a', index=False, header=False)\n",
    "    df_experiences.to_csv('/home/yassine/Desktop/End of studies Project/scraped_experiences.csv',mode='a', index=False, header=False)\n",
    "    df_education.to_csv('/home/yassine/Desktop/End of studies Project/scraped_education.csv',mode='a', index=False, header=False)\n",
    "    df_certification.to_csv('/home/yassine/Desktop/End of studies Project/scraped_certification.csv',mode='a', index=False, header=False)\n",
    "    df_courses.to_csv('/home/yassine/Desktop/End of studies Project/scraped_courses.csv',mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a032689",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Navigating the next page\n",
    "##################################\n",
    "\n",
    "def navigate_next_page(page_number,page_URL):\n",
    "    driver.get(page_URL)\n",
    "    time.sleep(2)\n",
    "    wait = WebDriverWait(driver, 4)\n",
    "    while True:\n",
    "        try:\n",
    "            next_btn = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"button.artdeco-pagination__button.artdeco-pagination__button--next\")))\n",
    "            next_btn.location_once_scrolled_into_view\n",
    "            time.sleep(0.2)\n",
    "            next_btn.click()\n",
    "            break\n",
    "        except:\n",
    "            driver.execute_script(\"window.scrollBy(0, arguments[0]);\", 600)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    print('Going to next page')\n",
    "    \n",
    "    current_url=driver.current_url\n",
    "    return current_url\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45724f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Core programe\n",
    "##################################\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "def core_prog():\n",
    "    # Login to LinkedIn\n",
    "    login()\n",
    "    time.sleep(5)\n",
    "    # Scrape the profiles of IT professionals and their projects, using for loop to loop over all pages\n",
    "    page_number=1\n",
    "    # Search for IT professionals\n",
    "    page_URL=search(' \"Data engineer\" OR \"Data scientist\" OR \"Software Engineer\"')\n",
    "    while (page_number<10):\n",
    "        time.sleep(5)\n",
    "        scrape_profiles()\n",
    "        time.sleep(5)\n",
    "        page_number+=1 \n",
    "        #Navigating to the next corresponding page\n",
    "        new_page_URL=navigate_next_page(page_number,page_URL)\n",
    "        print('Navigating to page :' + str(page_number))\n",
    "        page_URL= new_page_URL\n",
    "        time.sleep(6)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d9e2d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found education\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->Master 2 (M2), Data science<span class=\"white-space-pre\"> </span></span>\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->Mastère professionnel en génie biomédical et M2 en signaux systèmes et données, Technologies / techniciens d''ingénierie, autre<!-- --></span>\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->Mastère professionnel en génie biomédical , Biomédical<span class=\"white-space-pre\"> </span></span>\n",
      "found education\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->Master's degree, data science<span class=\"white-space-pre\"> </span></span>\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->licence fondamental en économie , Économétrie et économie quantitative<!-- --></span>\n",
      "found experience\n",
      "found education\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->Diplôme d'ingénieur, Ingénierie informatique<!-- --></span>\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->MASTÈRE PROFESSIONEL EN E-BUSINESS, économie digitale<!-- --></span>\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->Licence en informatique appliquée à la gestion, Informatique de gestion<span class=\"white-space-pre\"> </span></span>\n",
      "found certifications\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->NVIDIA<!-- --></span>\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->CertiProf<!-- --></span>\n",
      "None\n",
      "<span aria-hidden=\"true\"><!-- -->Google Ateliers Numériques<!-- --></span>\n",
      "found experience\n",
      "list index out of range\n",
      "list index out of range\n",
      "found education\n",
      "<span class=\"white-space-pre\"> </span>\n",
      "<span aria-hidden=\"true\"><!-- -->Diplome d'ingénieur, Ingénierie mécatronique, robotique et automatisation<!-- --></span>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Create the Firefox WebDriver\u001b[39;00m\n\u001b[1;32m     19\u001b[0m driver\u001b[39m.\u001b[39mmaximize_window()\n\u001b[0;32m---> 20\u001b[0m core_prog()\n\u001b[1;32m     21\u001b[0m driver\u001b[39m.\u001b[39mquit()\n",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36mcore_prog\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mwhile\u001b[39;00m (page_number\u001b[39m<\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[1;32m     15\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m5\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     scrape_profiles()\n\u001b[1;32m     17\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m5\u001b[39m)\n\u001b[1;32m     18\u001b[0m     page_number\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \n",
      "Cell \u001b[0;32mIn[15], line 80\u001b[0m, in \u001b[0;36mscrape_profiles\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mdiv[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meducation\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     79\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfound education\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m     educations_json \u001b[39m=\u001b[39m extract_achievements(section, \u001b[39m\"\u001b[39;49m\u001b[39meducation\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     81\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39meducations_json)\n\u001b[1;32m     82\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mprofile\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mcurrent_url\n",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m, in \u001b[0;36mextract_achievements\u001b[0;34m(head_section, category)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39melse\u001b[39;00m :\n\u001b[1;32m     21\u001b[0m     title \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m institute \u001b[39m=\u001b[39m institute\u001b[39m.\u001b[39;49mgroup(\u001b[39m0\u001b[39;49m) \u001b[39mif\u001b[39;00m institute \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m category \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meducation\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     29\u001b[0m     achievement_list\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     30\u001b[0m         {\n\u001b[1;32m     31\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: title,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m         }\n\u001b[1;32m     35\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Main program\n",
    "##################################\n",
    "r_expression = r'(?<=-\\>)[0-9a-zA-Z ·-]+'\n",
    "\n",
    "# Set up the web driver\n",
    "\n",
    "firefox_binary_path = \"/usr/bin/firefox\"\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = firefox_binary_path\n",
    "\n",
    "# Set the service with the executable path\n",
    "geckodriver_path = \"/usr/local/bin/geckodriver\"  # Replace with the actual path of geckodriver\n",
    "service = webdriver.firefox.service.Service(geckodriver_path)\n",
    "driver = webdriver.Firefox(options=options, service=service)\n",
    "\n",
    "# Create the Firefox WebDriver\n",
    "driver.maximize_window()\n",
    "core_prog()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5637d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
